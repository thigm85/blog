{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text search app with BERT models from python\n",
    "\n",
    "> Introducing pyvespa ML API. Cutting-edge Vespa search with few lines of code.\n",
    "\n",
    "- toc: true \n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [vespa, pyvespa, BERT, transformers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with a basic text search app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import ApplicationPackage, Field, FieldSet, RankProfile\n",
    "\n",
    "app_package = ApplicationPackage(name=\"cord19\")\n",
    "app_package.schema.add_fields(\n",
    "    Field(name = \"cord_uid\", type = \"string\", indexing = [\"attribute\", \"summary\"]),\n",
    "    Field(name = \"title\", type = \"string\", indexing = [\"index\", \"summary\"], index = \"enable-bm25\")\n",
    ")\n",
    "app_package.schema.add_field_set(\n",
    "    FieldSet(name = \"default\", fields = [\"title\"])\n",
    ")\n",
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(name = \"bm25\", first_phase = \"bm25(title)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download BERT tokenizer and model from the `transformers` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"google/bert_uncased_L-2_H-128_A-2\")  # This could be any pytorch BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"google/bert_uncased_L-2_H-128_A-2\")  # This could be any pytorch BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your Vespa model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-128_A-2 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from vespa.ml import BertModelConfig\n",
    "\n",
    "bert_config = BertModelConfig(\n",
    "    model_id=\"pretrained_bert_tiny\",\n",
    "    tokenizer=\"google/bert_uncased_L-2_H-128_A-2\",\n",
    "    model=\"google/bert_uncased_L-2_H-128_A-2\",    \n",
    "    query_input_size=32,\n",
    "    doc_input_size=96\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model based rank profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using framework PyTorch: 1.7.1\n",
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input token_type_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch'}\n",
      "Ensuring inputs are in correct order\n",
      "position_ids is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask', 'token_type_ids']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:194: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]\n",
      "/usr/local/lib/python3.9/site-packages/transformers/modeling_utils.py:1759: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert all(\n"
     ]
    }
   ],
   "source": [
    "from vespa.package import SecondPhaseRanking\n",
    "\n",
    "app_package.add_model_ranking(\n",
    "    model_config=bert_config,\n",
    "    inherits=\"default\",\n",
    "    first_phase=\"bm25(title)\",\n",
    "    second_phase=SecondPhaseRanking(\n",
    "        rerank_count=10, expression=\"logit1\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy your application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from vespa.package import VespaDocker\n",
    "\n",
    "vespa_docker = VespaDocker(port=8080)\n",
    "\n",
    "os.environ[\"WORK_DIR\"] = \"/Users/tmartins\"\n",
    "disk_folder = os.path.join(os.getenv(\"WORK_DIR\"), \"sample_application\")\n",
    "\n",
    "app = vespa_docker.deploy(\n",
    "    application_package = app_package,\n",
    "    disk_folder=disk_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "parsed_feed = read_csv(\"/Users/tmartins/projects/sw/blog/_notebooks/data/2021-01-18-cord19-deploy-bert-from-pyvespa/parsed_feed.csv\")\n",
    "parsed_feed = parsed_feed.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in parsed_feed.iterrows():\n",
    "    fields = {\n",
    "        \"cord_uid\": str(row[\"cord_uid\"]),\n",
    "        \"title\": str(row[\"title\"]),\n",
    "    }\n",
    "    fields.update(\n",
    "        bert_config.doc_fields(text = str(row[\"title\"]))\n",
    "    )\n",
    "    response = app.feed_data_point(\n",
    "        schema = \"cord19\",\n",
    "        data_id = str(row[\"cord_uid\"]),\n",
    "        fields = fields,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query your application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.query import QueryModel, RankProfile as Ranking, OR, QueryModelFeature\n",
    "\n",
    "result = app.query(\n",
    "    query=\"this is a test\", \n",
    "    query_model=QueryModel(\n",
    "        query_properties=[\n",
    "            QueryModelFeature(bert_config)\n",
    "        ],\n",
    "        match_phase = OR(),\n",
    "        rank_profile = Ranking(name=\"pretrained_bert_tiny\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.number_documents_retrieved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
