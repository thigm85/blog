{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "skilled-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-dubai",
   "metadata": {},
   "source": [
    "# Chapter 2 - The mathematical building blocks of Neural Networks\n",
    "> Notes about the book Deep Learning with python, 2nd edition\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [deep_learning, python, tensorflow, book]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-broad",
   "metadata": {},
   "source": [
    "## Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "hearing-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-fisher",
   "metadata": {},
   "source": [
    "## A first look at a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-possession",
   "metadata": {},
   "source": [
    "### MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-boutique",
   "metadata": {},
   "source": [
    "Task: classify grayscale images of handwritten digits (28 × 28 pixels) into their 10 categories (0 through 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "invalid-heavy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "11501568/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-pipeline",
   "metadata": {},
   "source": [
    "Training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rural-settlement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "incorrect-emerald",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "welsh-negative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-charleston",
   "metadata": {},
   "source": [
    "Test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "loaded-temple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "available-contents",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "israeli-crazy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-centre",
   "metadata": {},
   "source": [
    "### Define and compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-spoke",
   "metadata": {},
   "source": [
    "Define a basic multi-layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "numeric-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\"), \n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-invalid",
   "metadata": {},
   "source": [
    "Compile the model by specifying the optimization algorithm, the loss function and the metrics to track:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "opposed-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", \n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-microwave",
   "metadata": {},
   "source": [
    "### Pre-process the data as expected by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-credits",
   "metadata": {},
   "source": [
    "Transform the features from an array `(60000, 28, 28)` with values between `[0, 255]` to a flat array of size `(60000, 28 * 28)` of values `[0,1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fancy-newport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sacred-kidney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "southern-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "classified-trouble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rubber-latest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "anonymous-carnival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "certified-jordan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "smoking-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "active-cricket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "altered-richards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-allergy",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "elect-blanket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2423 - accuracy: 0.9297\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2323 - accuracy: 0.9331\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2227 - accuracy: 0.9359\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2133 - accuracy: 0.9384\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2044 - accuracy: 0.9410\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1957 - accuracy: 0.9437\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1881 - accuracy: 0.9460\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1805 - accuracy: 0.9483\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1732 - accuracy: 0.9505\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1665 - accuracy: 0.9524\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1603 - accuracy: 0.9538\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1541 - accuracy: 0.9560\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1487 - accuracy: 0.9576\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1433 - accuracy: 0.9593\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1384 - accuracy: 0.9604\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1337 - accuracy: 0.9622\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1290 - accuracy: 0.9634\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1247 - accuracy: 0.9642\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1208 - accuracy: 0.9658\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1173 - accuracy: 0.9669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14a481ee0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-lesson",
   "metadata": {},
   "source": [
    "### Predict with the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-declaration",
   "metadata": {},
   "source": [
    "Select the first 10 images of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "narrow-graph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digits = test_images[0:10]\n",
    "test_digits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-wilson",
   "metadata": {},
   "source": [
    "Compute predictions for the first 10 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "reflected-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-custody",
   "metadata": {},
   "source": [
    "Class probabilities for the first test images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cleared-belfast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-error",
   "metadata": {},
   "source": [
    "Pick the class with the highest probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "saving-vault",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-taste",
   "metadata": {},
   "source": [
    "Check what is the true label of the first test image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "derived-championship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-blame",
   "metadata": {},
   "source": [
    "### Evaluate the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "median-compilation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 18.4538 - accuracy: 0.9514\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "changing-albuquerque",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9514\n",
      "Test loss: 18.4538\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy: {test_acc:.4}\\nTest loss: {test_loss:.6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-stroke",
   "metadata": {},
   "source": [
    "## Data representation for neural networks: Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-honor",
   "metadata": {},
   "source": [
    "Tensors are the basic data structures used in Machine Learning. Tensor are multi-dimmentional arrays. In the context of tensors, a dimensional is also called an axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-disco",
   "metadata": {},
   "source": [
    "In deep learning, you'll generally manipulate tensors with ranks 0 to 4, although you may go up to 5 if you process video data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-democracy",
   "metadata": {},
   "source": [
    "### Scalars (rank-0 tensors, 0D tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ahead-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "helpful-paris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-internship",
   "metadata": {},
   "source": [
    "### Vectors (rank-1 tensors, 1D tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "registered-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([12, 3, 6, 14, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "noble-haiti",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-jewel",
   "metadata": {},
   "source": [
    "### Matrices (rank-2 tensors, 2D tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "looking-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(\n",
    "    [\n",
    "        [5, 78, 2, 34, 0],\n",
    "        [6, 79, 3, 35, 1],\n",
    "        [7, 80, 4, 36, 2]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "sticky-membership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-agreement",
   "metadata": {},
   "source": [
    "### Rank-3 and higher rank tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-injury",
   "metadata": {},
   "source": [
    "If you pack such matrices in a new array, you obtain a rank-3 tensor (or 3D tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "economic-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(\n",
    "    [\n",
    "        [\n",
    "            [5, 78, 2, 34, 0],\n",
    "            [6, 79, 3, 35, 1],\n",
    "            [7, 80, 4, 36, 2]\n",
    "        ],\n",
    "        [\n",
    "            [5, 78, 2, 34, 0],\n",
    "            [6, 79, 3, 35, 1],\n",
    "            [7, 80, 4, 36, 2]\n",
    "        ],\n",
    "        [\n",
    "            [5, 78, 2, 34, 0],\n",
    "            [6, 79, 3, 35, 1],\n",
    "            [7, 80, 4, 36, 2]\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "conventional-horror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-niagara",
   "metadata": {},
   "source": [
    "### Tensor key attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-conviction",
   "metadata": {},
   "source": [
    "1. Number of axis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "loose-commerce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-basketball",
   "metadata": {},
   "source": [
    "2. Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "broad-clock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-hardwood",
   "metadata": {},
   "source": [
    "3. Data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "severe-photograph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-grave",
   "metadata": {},
   "source": [
    "### Manipulating tensors in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "flush-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-cause",
   "metadata": {},
   "source": [
    "Slicing arrays. The following three statements are equivalent. It selects 90 images, from indices 10 to 99:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "continuous-chick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "absolute-symposium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "nuclear-plane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-collapse",
   "metadata": {},
   "source": [
    "Select 14x14 pixels in the bottom-right corner of all images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "front-highway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[:, 14:, 14:]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-target",
   "metadata": {},
   "source": [
    "Select 14x14 pixels from the middle of all images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "gothic-lodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[:, 7:-7, 7:-7]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-ambassador",
   "metadata": {},
   "source": [
    "### Real-world example of data tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-plane",
   "metadata": {},
   "source": [
    "* Vector data: 2D-tensor `(number_samples, features)`\n",
    "* Timeseries or sequence data: 3D-tensor `(number_samples, timesteps, features)`\n",
    "* Images: 4D-tensor `(number_samples, height, width, channels)`\n",
    "* Video: 5D-tensor `(number_samples, frames, height, width, channels)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-manufacturer",
   "metadata": {},
   "source": [
    "## The gears of neural networks: Tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-specific",
   "metadata": {},
   "source": [
    "### Layer as a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-dover",
   "metadata": {},
   "source": [
    "The dense layer with a rectified linear unit activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "radio-narrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x14a487310>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Dense(512, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-bermuda",
   "metadata": {},
   "source": [
    "The layer above can be interepreted as the following function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-dominant",
   "metadata": {},
   "source": [
    "```\n",
    "output = max(dot(input, W) + b, 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-booth",
   "metadata": {},
   "source": [
    "### Element-wise operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-lawsuit",
   "metadata": {},
   "source": [
    "Element-wise operations are carried out by optimized NumPy code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-milwaukee",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-trash",
   "metadata": {},
   "source": [
    "When possible, and if there’s no ambiguity, the smaller tensor will be broadcast to match the shape of the larger tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "iraqi-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random((32, 10))\n",
    "y = np.random.random((10,))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "uniform-plymouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = X + y\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "educated-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "double-milan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 32, 10)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.maximum(x, y) \n",
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-angola",
   "metadata": {},
   "source": [
    "### Tensor-product (dot-product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-factor",
   "metadata": {},
   "source": [
    "* Dot-product between vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-cartoon",
   "metadata": {},
   "source": [
    "The dot-product between two vectors is a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-missouri",
   "metadata": {},
   "source": [
    "$$x . y = \\sum _{i=1}^{n} x_i * y_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-review",
   "metadata": {},
   "source": [
    "* Dot-product between a matrix and a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-inside",
   "metadata": {},
   "source": [
    "The dot-product between a matrix X and a vector y is a vector whose element $i$ is the dot-product of the vector y and the $i$-th row of X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-bacteria",
   "metadata": {},
   "source": [
    "* Higher dimension dot-products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-missile",
   "metadata": {},
   "source": [
    "We can take higher dimension dot-product, as long as the last dimension of the first tensor match the first dimension of the second tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-polyester",
   "metadata": {},
   "source": [
    "`(a, b, c, d) . (d,) -> (a,b,c)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-delta",
   "metadata": {},
   "source": [
    "`(a, b, c, d) . (d, e) -> (a, b, c, e)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-freight",
   "metadata": {},
   "source": [
    "### Tensor reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-ranch",
   "metadata": {},
   "source": [
    "Reshaping a tensor means rearranging its rows and columns to match a target shape. Naturally, the reshaped tensor has the same total number of coefficients as the initial tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "attempted-bolivia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "              [2., 3.],\n",
    "              [4., 5.]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "metric-anthropology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "specified-extent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2.],\n",
       "       [3., 4., 5.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((2, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-bradley",
   "metadata": {},
   "source": [
    "* Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "sized-discrimination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 300)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-burke",
   "metadata": {},
   "source": [
    "### Geometric interpretation of tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-blackberry",
   "metadata": {},
   "source": [
    "In general, elementary geometric operations such as *translation*, *rotation*, *scaling* and so on can be expressed as tensor operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-ceiling",
   "metadata": {},
   "source": [
    "* *Translation*: Translating a 2D object can be implemented as the sum of two vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-grammar",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "    \\text{Horizontal factor} \\\\\n",
    "    \\text{Vertical factor} \\\\\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "    x \\\\\n",
    "    y \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-roberts",
   "metadata": {},
   "source": [
    "* *Rotation*: A counterclockwise rotation of a 2D vector by an angle $\\theta$ can be achieved via a dot-product with a 2 x 2 matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-landing",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "    cos(\\theta) & -sin(\\theta) \\\\\n",
    "    sin(\\theta) & cos(\\theta) \\\\\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "    x \\\\\n",
    "    y \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-hepatitis",
   "metadata": {},
   "source": [
    "* *Scaling*: scaling of a 2D object can also be accomplished by a dot-product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-monthly",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "    factor_x & 0 \\\\\n",
    "    0 & factor_y \\\\\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "    x \\\\\n",
    "    y \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-benjamin",
   "metadata": {},
   "source": [
    "* *Linear transform*: A dot-product with an arbitrary matrix implements a linear transform. Rotation and Scaling are examples of linear transforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-digit",
   "metadata": {},
   "source": [
    "$$W \\cdot x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-intro",
   "metadata": {},
   "source": [
    "* *Affine transform*: It is a combination of a linear transform and a translation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-exercise",
   "metadata": {},
   "source": [
    "$$W \\cdot x + b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-league",
   "metadata": {},
   "source": [
    "* *Importance of activation functions*: A sequence of affine transforms is equivalent to an affine transform. So a sequence of `Dense` layers without activation function would still be equivalent to a single `Dense` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-sample",
   "metadata": {},
   "source": [
    "We just saw that a tensor operation is equivalent to a geometric transformation. Since a neural network is a series of tensor operations, we can say that a neural network is a very complex geometric transformation in a high-dimensional space, implemented via a series of simple steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-hierarchy",
   "metadata": {},
   "source": [
    "## The engine of neural networks: Gradient-based optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-commerce",
   "metadata": {},
   "source": [
    "Assume our network is represented by `output = relu(dot(input, W)+b)`. `W` and `b` are the parameters of the model and are initially randomly initialized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-bailey",
   "metadata": {},
   "source": [
    "By training the neural network, we will gradually adapt `W` and `b` with the objective of minimizing a loss function between the model prediction `y_pred` and the observed data `y_true`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-notification",
   "metadata": {},
   "source": [
    "A training loop involves repeating the following steps until the loss seems sufficiently low:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-luxembourg",
   "metadata": {},
   "source": [
    "1. Draw a batch of training samples, `x`, and corresponding targets, `y_true`.\n",
    "2. Run the model on `x` (a step called the forward pass) to obtain predictions, `y_pred`.\n",
    "3. Compute the loss of the model on the batch, a measure of the mismatch between `y_pred` and `y_true`.\n",
    "4. Update all weights of the model in a way that slightly reduces the loss on this batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-project",
   "metadata": {},
   "source": [
    "Step 4 is carried out by gradient descent, which requires that the loss function be differentiable with respect to the model learnable parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-oregon",
   "metadata": {},
   "source": [
    "### What is a derivative?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-nursing",
   "metadata": {},
   "source": [
    "Geometric explanation of the derivative of a continuous and smooth function. The derivative represents the local slope of the curve of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-irrigation",
   "metadata": {},
   "source": [
    "### Derivative of a tensor operation: The gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-yellow",
   "metadata": {},
   "source": [
    "Gradients are just the generalization of the concept of derivatives to functions that take tensors as inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-transmission",
   "metadata": {},
   "source": [
    "Assuming a model `y = f(W)`, where `W` is a tensor with model coefficients, `grad(loss, W0)` can be interpreted as the tensor describing the direction of steepest ascent of `loss_value = f(W)` around `W0`. We can reduce `loss_value = f(W)` by moving `W` inn the oposite direction from the gradient: `W_1 = W_0 - step * grad(loss, W0)`. `step` is a small scaling factor that is needed because the gradient is a local approximation of the curvature of the function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-recipient",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-candy",
   "metadata": {},
   "source": [
    "Mini-batch stochastic gradient descent draws random batches of data and apply one step of gradient descent to decrease the loss function by a little bit. The process is repeated until convergence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-television",
   "metadata": {},
   "source": [
    "There exists variations of SGD, such as momentum SDG that uses not only the current gradient but also previous gradient values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-observer",
   "metadata": {},
   "source": [
    "### Chaining derivatives: The backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-offense",
   "metadata": {},
   "source": [
    "* Chain rule exemplified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fghj(x):\n",
    "    x1 = j(x)\n",
    "    x2 = h(x1)\n",
    "    x3 = g(x2)\n",
    "    y = f(x3)\n",
    "    return y\n",
    " \n",
    "grad(y, x) == grad(y, x3) * grad(x3, x2) * grad(x2, x1) * grad(x1, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-salad",
   "metadata": {},
   "source": [
    "* Automatic differentiation with computation graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-scale",
   "metadata": {},
   "source": [
    "A computation graph is a directed acyclic graph of tensor operations. The chain rule says that you can obtain the derivative of a node with the respect of another node by multiplying the derivatives for each edge along the path linking the two nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-monday",
   "metadata": {},
   "source": [
    "* Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-competition",
   "metadata": {},
   "source": [
    "Backpropagation is simply the application of the chain rule to a computation graph. Backpropagation starts with the final loss value and works backward from the top layers to the bottom layers, computing the contribution that each parameter had in the loss value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-checkout",
   "metadata": {},
   "source": [
    "* TensorFlow gradient tape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-investment",
   "metadata": {},
   "source": [
    "It's a Python scope that will \"record\" the tensor operations that run inside it, in the form of a computation graph (sometimes called a “tape”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "specified-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# gradient wrt a scalar variable\n",
    "x = tf.Variable(0.)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "crucial-hours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_of_y_wrt_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "empty-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient wrt a tensor variable\n",
    "x = tf.Variable(tf.random.uniform((2, 2)))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3 \n",
    "grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ignored-radiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_of_y_wrt_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "third-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient wrt a list of variables\n",
    "W = tf.Variable(tf.random.uniform((2, 2)))\n",
    "b = tf.Variable(tf.zeros((2,)))\n",
    "x = tf.random.uniform((2, 2)) \n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(x, W) + b                       \n",
    "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "direct-calculator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[1.2138343 , 1.2138343 ],\n",
       "        [0.50162864, 0.50162864]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_of_y_wrt_W_and_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-shield",
   "metadata": {},
   "source": [
    "## Reimplementing our first example from scratch in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-destiny",
   "metadata": {},
   "source": [
    "### A simple dense class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-receipt",
   "metadata": {},
   "source": [
    "`output = activation(dot(W,input)+b)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "annual-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "  \n",
    "class NaiveDense:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.activation = activation\n",
    " \n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
    "        self.W = tf.Variable(w_initial_value)\n",
    "  \n",
    "        b_shape = (output_size,)\n",
    "        b_initial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial_value)\n",
    "  \n",
    "    def __call__(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "  \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-smart",
   "metadata": {},
   "source": [
    "### A simple sequential class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "liked-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "  \n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "  \n",
    "    @property \n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights += layer.weights\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-houston",
   "metadata": {},
   "source": [
    "### Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "royal-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveSequential([\n",
    "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "]) \n",
    "assert len(model.weights) == 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-daniel",
   "metadata": {},
   "source": [
    "### A batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "shaped-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "  \n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    " \n",
    "    def next(self):\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-toronto",
   "metadata": {},
   "source": [
    "### Running one training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "capital-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_training_step(model, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            labels_batch, predictions\n",
    "        )\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-nutrition",
   "metadata": {},
   "source": [
    "Manual implementation of the update step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hired-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3 \n",
    "  \n",
    "def update_weights(gradients, weights):\n",
    "    for g, w in zip(gradients, weights):\n",
    "        w.assign_sub(g * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-malaysia",
   "metadata": {},
   "source": [
    "In practice, you would almost never implement a weight update step like this by hand. Instead, you would use an Optimizer instance from Keras, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "potential-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "  \n",
    "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
    "  \n",
    "def update_weights(gradients, weights):\n",
    "    optimizer.apply_gradients(zip(gradients, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-litigation",
   "metadata": {},
   "source": [
    "### The full training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "laughing-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, images, labels, epochs, batch_size=128):\n",
    "    for epoch_counter in range(epochs):\n",
    "        print(f\"Epoch {epoch_counter}\")\n",
    "        batch_generator = BatchGenerator(images, labels)\n",
    "        for batch_counter in range(batch_generator.num_batches):\n",
    "            images_batch, labels_batch = batch_generator.next()\n",
    "            loss = one_training_step(model, images_batch, labels_batch)\n",
    "            if batch_counter % 100 == 0:\n",
    "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "amino-organic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "loss at batch 0: 3.42\n",
      "loss at batch 100: 2.25\n",
      "loss at batch 200: 2.20\n",
      "loss at batch 300: 2.08\n",
      "loss at batch 400: 2.19\n",
      "Epoch 1\n",
      "loss at batch 0: 1.91\n",
      "loss at batch 100: 1.89\n",
      "loss at batch 200: 1.83\n",
      "loss at batch 300: 1.69\n",
      "loss at batch 400: 1.79\n",
      "Epoch 2\n",
      "loss at batch 0: 1.58\n",
      "loss at batch 100: 1.59\n",
      "loss at batch 200: 1.50\n",
      "loss at batch 300: 1.41\n",
      "loss at batch 400: 1.47\n",
      "Epoch 3\n",
      "loss at batch 0: 1.32\n",
      "loss at batch 100: 1.34\n",
      "loss at batch 200: 1.24\n",
      "loss at batch 300: 1.19\n",
      "loss at batch 400: 1.24\n",
      "Epoch 4\n",
      "loss at batch 0: 1.12\n",
      "loss at batch 100: 1.16\n",
      "loss at batch 200: 1.04\n",
      "loss at batch 300: 1.03\n",
      "loss at batch 400: 1.08\n",
      "Epoch 5\n",
      "loss at batch 0: 0.98\n",
      "loss at batch 100: 1.02\n",
      "loss at batch 200: 0.91\n",
      "loss at batch 300: 0.91\n",
      "loss at batch 400: 0.96\n",
      "Epoch 6\n",
      "loss at batch 0: 0.87\n",
      "loss at batch 100: 0.91\n",
      "loss at batch 200: 0.80\n",
      "loss at batch 300: 0.82\n",
      "loss at batch 400: 0.88\n",
      "Epoch 7\n",
      "loss at batch 0: 0.79\n",
      "loss at batch 100: 0.83\n",
      "loss at batch 200: 0.73\n",
      "loss at batch 300: 0.75\n",
      "loss at batch 400: 0.81\n",
      "Epoch 8\n",
      "loss at batch 0: 0.73\n",
      "loss at batch 100: 0.76\n",
      "loss at batch 200: 0.66\n",
      "loss at batch 300: 0.70\n",
      "loss at batch 400: 0.76\n",
      "Epoch 9\n",
      "loss at batch 0: 0.68\n",
      "loss at batch 100: 0.70\n",
      "loss at batch 200: 0.62\n",
      "loss at batch 300: 0.65\n",
      "loss at batch 400: 0.72\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "  \n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255  \n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255 \n",
    "  \n",
    "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-mixer",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "joint-peace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy()\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "matches = predicted_labels == test_labels\n",
    "print(f\"accuracy: {matches.mean():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
