{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "skilled-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-dubai",
   "metadata": {},
   "source": [
    "# Chapter 2: The mathematical building blocks of Neural Networks\n",
    "> Notes about the book Deep Learning with python, 2nd edition\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [tensorflow, datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-broad",
   "metadata": {},
   "source": [
    "## Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "hearing-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-fisher",
   "metadata": {},
   "source": [
    "## A first look at a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-possession",
   "metadata": {},
   "source": [
    "### MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-boutique",
   "metadata": {},
   "source": [
    "Task: classify grayscale images of handwritten digits (28 Ã— 28 pixels) into their 10 categories (0 through 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "invalid-heavy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "11501568/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-pipeline",
   "metadata": {},
   "source": [
    "Training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rural-settlement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "incorrect-emerald",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "welsh-negative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-charleston",
   "metadata": {},
   "source": [
    "Test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "loaded-temple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "available-contents",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "israeli-crazy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-centre",
   "metadata": {},
   "source": [
    "### Define and compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-spoke",
   "metadata": {},
   "source": [
    "Define a basic multi-layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "numeric-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\"), \n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-invalid",
   "metadata": {},
   "source": [
    "Compile the model by specifying the optimization algorithm, the loss function and the metrics to track:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "opposed-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", \n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-microwave",
   "metadata": {},
   "source": [
    "### Pre-process the data as expected by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-credits",
   "metadata": {},
   "source": [
    "Transform the features from an array `(60000, 28, 28)` with values between `[0, 255]` to a flat array of size `(60000, 28 * 28)` of values `[0,1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fancy-newport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sacred-kidney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "southern-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "classified-trouble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rubber-latest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "communist-expression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "compliant-customs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "documentary-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "complicated-consequence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "prescribed-spokesman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-gossip",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "turkish-rouge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2423 - accuracy: 0.9297\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2323 - accuracy: 0.9331\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2227 - accuracy: 0.9359\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2133 - accuracy: 0.9384\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2044 - accuracy: 0.9410\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1957 - accuracy: 0.9437\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1881 - accuracy: 0.9460\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1805 - accuracy: 0.9483\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1732 - accuracy: 0.9505\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1665 - accuracy: 0.9524\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1603 - accuracy: 0.9538\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1541 - accuracy: 0.9560\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1487 - accuracy: 0.9576\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1433 - accuracy: 0.9593\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1384 - accuracy: 0.9604\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1337 - accuracy: 0.9622\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1290 - accuracy: 0.9634\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1247 - accuracy: 0.9642\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1208 - accuracy: 0.9658\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1173 - accuracy: 0.9669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14a481ee0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-poultry",
   "metadata": {},
   "source": [
    "### Predict with the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-steam",
   "metadata": {},
   "source": [
    "Select the first 10 images of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "starting-salmon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digits = test_images[0:10]\n",
    "test_digits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-drain",
   "metadata": {},
   "source": [
    "Compute predictions for the first 10 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "optional-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-supplement",
   "metadata": {},
   "source": [
    "Class probabilities for the first test images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "executive-argentina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-directive",
   "metadata": {},
   "source": [
    "Pick the class with the highest probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fundamental-creek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-gathering",
   "metadata": {},
   "source": [
    "Check what is the true label of the first test image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "sweet-personal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-silicon",
   "metadata": {},
   "source": [
    "### Evaluate the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "criminal-immune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 18.4538 - accuracy: 0.9514\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "surprised-reader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9514\n",
      "Test loss: 18.4538\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy: {test_acc:.4}\\nTest loss: {test_loss:.6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-photograph",
   "metadata": {},
   "source": [
    "## Data representation for neural networks: Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-burns",
   "metadata": {},
   "source": [
    "Tensors are the basic data structures used in Machine Learning. Tensor are multi-dimmentional arrays. In the context of tensors, a dimensional is also called an axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-imaging",
   "metadata": {},
   "source": [
    "In deep learning, you'll generally manipulate tensors with ranks 0 to 4, although you may go up to 5 if you process video data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-carry",
   "metadata": {},
   "source": [
    "### Scalars (rank-0 tensors, 0D tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "persistent-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "direct-canon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-longitude",
   "metadata": {},
   "source": [
    "### Vectors (rank-1 tensors, 1D tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "green-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([12, 3, 6, 14, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "legitimate-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-simple",
   "metadata": {},
   "source": [
    "### Matrices (rank-2 tensors, 2D tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "unsigned-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(\n",
    "    [\n",
    "        [5, 78, 2, 34, 0],\n",
    "        [6, 79, 3, 35, 1],\n",
    "        [7, 80, 4, 36, 2]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "chinese-charlotte",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-alpha",
   "metadata": {},
   "source": [
    "### Rank-3 and higher rank tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-endorsement",
   "metadata": {},
   "source": [
    "If you pack such matrices in a new array, you obtain a rank-3 tensor (or 3D tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "architectural-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(\n",
    "    [\n",
    "        [\n",
    "            [5, 78, 2, 34, 0],\n",
    "            [6, 79, 3, 35, 1],\n",
    "            [7, 80, 4, 36, 2]\n",
    "        ],\n",
    "        [\n",
    "            [5, 78, 2, 34, 0],\n",
    "            [6, 79, 3, 35, 1],\n",
    "            [7, 80, 4, 36, 2]\n",
    "        ],\n",
    "        [\n",
    "            [5, 78, 2, 34, 0],\n",
    "            [6, 79, 3, 35, 1],\n",
    "            [7, 80, 4, 36, 2]\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "worthy-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-anchor",
   "metadata": {},
   "source": [
    "### Tensor key attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-couple",
   "metadata": {},
   "source": [
    "1. Number of axis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "changed-walker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-andrew",
   "metadata": {},
   "source": [
    "2. Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "elementary-invitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-accuracy",
   "metadata": {},
   "source": [
    "3. Data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "unusual-ecology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-milan",
   "metadata": {},
   "source": [
    "### Manipulating tensors in NumPy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
