{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "skilled-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-dubai",
   "metadata": {},
   "source": [
    "# Chapter 2 - The mathematical building blocks of Neural Networks\n",
    "> Notes about the book Deep Learning with python, 2nd edition\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [deep_learning, python, tensorflow, book]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-broad",
   "metadata": {},
   "source": [
    "## Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "hearing-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-fisher",
   "metadata": {},
   "source": [
    "## A first look at a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-possession",
   "metadata": {},
   "source": [
    "### MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-boutique",
   "metadata": {},
   "source": [
    "Task: classify grayscale images of handwritten digits (28 × 28 pixels) into their 10 categories (0 through 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "invalid-heavy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "11501568/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-pipeline",
   "metadata": {},
   "source": [
    "Training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rural-settlement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "incorrect-emerald",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "welsh-negative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-charleston",
   "metadata": {},
   "source": [
    "Test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "loaded-temple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "available-contents",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "israeli-crazy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-centre",
   "metadata": {},
   "source": [
    "### Define and compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-spoke",
   "metadata": {},
   "source": [
    "Define a basic multi-layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "numeric-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\"), \n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-invalid",
   "metadata": {},
   "source": [
    "Compile the model by specifying the optimization algorithm, the loss function and the metrics to track:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "opposed-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", \n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-microwave",
   "metadata": {},
   "source": [
    "### Pre-process the data as expected by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-credits",
   "metadata": {},
   "source": [
    "Transform the features from an array `(60000, 28, 28)` with values between `[0, 255]` to a flat array of size `(60000, 28 * 28)` of values `[0,1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fancy-newport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sacred-kidney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "southern-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "classified-trouble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rubber-latest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "anonymous-carnival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "certified-jordan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "smoking-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "active-cricket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "altered-richards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-allergy",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "elect-blanket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2423 - accuracy: 0.9297\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2323 - accuracy: 0.9331\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2227 - accuracy: 0.9359\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2133 - accuracy: 0.9384\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2044 - accuracy: 0.9410\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1957 - accuracy: 0.9437\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1881 - accuracy: 0.9460\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1805 - accuracy: 0.9483\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1732 - accuracy: 0.9505\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1665 - accuracy: 0.9524\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1603 - accuracy: 0.9538\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1541 - accuracy: 0.9560\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1487 - accuracy: 0.9576\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1433 - accuracy: 0.9593\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1384 - accuracy: 0.9604\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1337 - accuracy: 0.9622\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1290 - accuracy: 0.9634\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1247 - accuracy: 0.9642\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1208 - accuracy: 0.9658\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1173 - accuracy: 0.9669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14a481ee0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-lesson",
   "metadata": {},
   "source": [
    "### Predict with the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-declaration",
   "metadata": {},
   "source": [
    "Select the first 10 images of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "narrow-graph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digits = test_images[0:10]\n",
    "test_digits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-wilson",
   "metadata": {},
   "source": [
    "Compute predictions for the first 10 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "reflected-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-custody",
   "metadata": {},
   "source": [
    "Class probabilities for the first test images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cleared-belfast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-error",
   "metadata": {},
   "source": [
    "Pick the class with the highest probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "saving-vault",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-taste",
   "metadata": {},
   "source": [
    "Check what is the true label of the first test image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "derived-championship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-blame",
   "metadata": {},
   "source": [
    "### Evaluate the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "median-compilation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 18.4538 - accuracy: 0.9514\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "changing-albuquerque",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9514\n",
      "Test loss: 18.4538\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy: {test_acc:.4}\\nTest loss: {test_loss:.6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-stroke",
   "metadata": {},
   "source": [
    "## Data representation for neural networks: Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-honor",
   "metadata": {},
   "source": [
    "Tensors are the basic data structures used in Machine Learning. Tensor are multi-dimmentional arrays. In the context of tensors, a dimensional is also called an axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-disco",
   "metadata": {},
   "source": [
    "In deep learning, you'll generally manipulate tensors with ranks 0 to 4, although you may go up to 5 if you process video data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-democracy",
   "metadata": {},
   "source": [
    "### Scalars (rank-0 tensors, 0D tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ahead-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "helpful-paris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-internship",
   "metadata": {},
   "source": [
    "### Vectors (rank-1 tensors, 1D tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "registered-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([12, 3, 6, 14, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "noble-haiti",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-jewel",
   "metadata": {},
   "source": [
    "### Matrices (rank-2 tensors, 2D tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "looking-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(\n",
    "    [\n",
    "        [5, 78, 2, 34, 0],\n",
    "        [6, 79, 3, 35, 1],\n",
    "        [7, 80, 4, 36, 2]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "sticky-membership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-agreement",
   "metadata": {},
   "source": [
    "### Rank-3 and higher rank tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-injury",
   "metadata": {},
   "source": [
    "If you pack such matrices in a new array, you obtain a rank-3 tensor (or 3D tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "economic-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(\n",
    "    [\n",
    "        [\n",
    "            [5, 78, 2, 34, 0],\n",
    "            [6, 79, 3, 35, 1],\n",
    "            [7, 80, 4, 36, 2]\n",
    "        ],\n",
    "        [\n",
    "            [5, 78, 2, 34, 0],\n",
    "            [6, 79, 3, 35, 1],\n",
    "            [7, 80, 4, 36, 2]\n",
    "        ],\n",
    "        [\n",
    "            [5, 78, 2, 34, 0],\n",
    "            [6, 79, 3, 35, 1],\n",
    "            [7, 80, 4, 36, 2]\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "conventional-horror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-niagara",
   "metadata": {},
   "source": [
    "### Tensor key attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-conviction",
   "metadata": {},
   "source": [
    "1. Number of axis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "loose-commerce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-basketball",
   "metadata": {},
   "source": [
    "2. Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "broad-clock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-hardwood",
   "metadata": {},
   "source": [
    "3. Data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "severe-photograph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-grave",
   "metadata": {},
   "source": [
    "### Manipulating tensors in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "flush-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-cause",
   "metadata": {},
   "source": [
    "Slicing arrays. The following three statements are equivalent. It selects 90 images, from indices 10 to 99:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "continuous-chick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "absolute-symposium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "nuclear-plane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-collapse",
   "metadata": {},
   "source": [
    "Select 14x14 pixels in the bottom-right corner of all images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "front-highway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[:, 14:, 14:]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-target",
   "metadata": {},
   "source": [
    "Select 14x14 pixels from the middle of all images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "gothic-lodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[:, 7:-7, 7:-7]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-ambassador",
   "metadata": {},
   "source": [
    "### Real-world example of data tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-plane",
   "metadata": {},
   "source": [
    "* Vector data: 2D-tensor `(number_samples, features)`\n",
    "* Timeseries or sequence data: 3D-tensor `(number_samples, timesteps, features)`\n",
    "* Images: 4D-tensor `(number_samples, height, width, channels)`\n",
    "* Video: 5D-tensor `(number_samples, frames, height, width, channels)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-manufacturer",
   "metadata": {},
   "source": [
    "## The gears of neural networks: Tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-specific",
   "metadata": {},
   "source": [
    "### Layer as a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-dover",
   "metadata": {},
   "source": [
    "The dense layer with a rectified linear unit activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "radio-narrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x14a487310>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Dense(512, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-bermuda",
   "metadata": {},
   "source": [
    "The layer above can be interepreted as the following function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-dominant",
   "metadata": {},
   "source": [
    "```\n",
    "output = max(dot(input, W) + b, 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-booth",
   "metadata": {},
   "source": [
    "### Element-wise operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-lawsuit",
   "metadata": {},
   "source": [
    "Element-wise operations are carried out by optimized NumPy code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-milwaukee",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-trash",
   "metadata": {},
   "source": [
    "When possible, and if there’s no ambiguity, the smaller tensor will be broadcast to match the shape of the larger tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "impaired-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random((32, 10))\n",
    "y = np.random.random((10,))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "indie-palace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = X + y\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "senior-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "allied-synthesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 32, 10)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.maximum(x, y) \n",
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-jones",
   "metadata": {},
   "source": [
    "### Tensor-product (dot-product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-healthcare",
   "metadata": {},
   "source": [
    "* Dot-product between vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-recovery",
   "metadata": {},
   "source": [
    "The dot-product between two vectors is a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-circular",
   "metadata": {},
   "source": [
    "$$x . y = \\sum _{i=1}^{n} x_i * y_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-element",
   "metadata": {},
   "source": [
    "* Dot-product between a matrix and a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-builder",
   "metadata": {},
   "source": [
    "The dot-product between a matrix X and a vector y is a vector whose element $i$ is the dot-product of the vector y and the $i$-th row of X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-airfare",
   "metadata": {},
   "source": [
    "* Higher dimension dot-products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-picture",
   "metadata": {},
   "source": [
    "We can take higher dimension dot-product, as long as the last dimension of the first tensor match the first dimension of the second tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-secretariat",
   "metadata": {},
   "source": [
    "`(a, b, c, d) . (d,) -> (a,b,c)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-elephant",
   "metadata": {},
   "source": [
    "`(a, b, c, d) . (d, e) -> (a, b, c, e)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-emperor",
   "metadata": {},
   "source": [
    "### Tensor reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-egypt",
   "metadata": {},
   "source": [
    "Reshaping a tensor means rearranging its rows and columns to match a target shape. Naturally, the reshaped tensor has the same total number of coefficients as the initial tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "hairy-despite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "              [2., 3.],\n",
    "              [4., 5.]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "confused-organizer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "improving-uganda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2.],\n",
       "       [3., 4., 5.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((2, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-supervision",
   "metadata": {},
   "source": [
    "* Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cardiac-inspection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 300)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-australian",
   "metadata": {},
   "source": [
    "### Geometric interpretation of tensor operations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
