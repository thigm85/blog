{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "characteristic-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-shopper",
   "metadata": {},
   "source": [
    "# pyvespa release: version 0.5.0\n",
    "\n",
    "> Summary of the improvements introduced in pyvespa 0.5.0\n",
    "\n",
    "- toc: true \n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [vespa, pyvespa, search, search evaluation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-annex",
   "metadata": {},
   "source": [
    "We just made a series of improvements to pyvespa evaluation framework. This post summarizes the changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-disney",
   "metadata": {},
   "source": [
    "## Connect to a sample app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-following",
   "metadata": {},
   "source": [
    "We will use the [cord19 app](https://cord19.vespa.ai/) in our demonstration. The focus here is not on this specific app, but to use a few sample queries to illustrate the latest changes in pyvespa `0.5.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "through-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.application import Vespa\n",
    "\n",
    "app = Vespa(url = \"https://api.cord19.vespa.ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-charles",
   "metadata": {},
   "source": [
    "## Flexible QueryModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-slave",
   "metadata": {},
   "source": [
    "A [QueryModel](https://pyvespa.readthedocs.io/en/latest/reference-api.html#query-model) is an abstraction that encapsulates all the relevant information controlling how your app match and rank documents. A `QueryModel` can be used for [querying](https://pyvespa.readthedocs.io/en/latest/reference-api.html#vespa.application.Vespa.query), [evaluating](https://pyvespa.readthedocs.io/en/latest/reference-api.html#vespa.application.Vespa.evaluate) and [collecting data](https://pyvespa.readthedocs.io/en/latest/reference-api.html#vespa.application.Vespa.collect_training_data) from your app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-spirituality",
   "metadata": {},
   "source": [
    "Before version `0.5.0`, the only way to build a `QueryModel` was by specifying arguments like `match_phase` and `rank_profile` using the pyvespa API, such as [match operators](https://pyvespa.readthedocs.io/en/latest/reference-api.html#match-phase). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tropical-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.query import QueryModel, RankProfile, OR\n",
    "\n",
    "standard_query_model = QueryModel(\n",
    "    name=\"or_bm25\",\n",
    "    match_phase = OR(),\n",
    "    rank_profile = RankProfile(name=\"bm25\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-continuity",
   "metadata": {},
   "source": [
    "Starting in version `0.5.0` we can bypass the pyvespa high-level API and create a `QueryModel` with the full flexibility of the [Vespa Query API](https://docs.vespa.ai/en/reference/query-api-reference.html). This is useful for use cases not covered by the pyvespa API and for users that are familiar with and prefer to work with the Vespa Query API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "existing-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def body_function(query):\n",
    "    body = {'yql': 'select * from sources * where userQuery();',\n",
    "            'query': query,\n",
    "            'type': 'any',\n",
    "            'ranking': {'profile': 'bm25', 'listFeatures': 'false'}}\n",
    "    return body\n",
    "\n",
    "flexible_query_model = QueryModel(body_function = body_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-joint",
   "metadata": {},
   "source": [
    "The `flexible_query_model` defined above is equivalent to the `standard_query_model`, as we can see when querying the `app`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "attached-posting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id:covid-19:doc::31328</td>\n",
       "      <td>11.282253</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>id:covid-19:doc::142863</td>\n",
       "      <td>11.282253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>id:covid-19:doc::187156</td>\n",
       "      <td>11.266751</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                   doc_id      score  rank\n",
       "0    0   id:covid-19:doc::31328  11.282253     0\n",
       "1    0  id:covid-19:doc::142863  11.282253     1\n",
       "2    0  id:covid-19:doc::187156  11.266751     2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_result = app.query(query=\"this is a test\", query_model=standard_query_model)\n",
    "standard_result.get_hits().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "spoken-picking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id:covid-19:doc::31328</td>\n",
       "      <td>11.282253</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>id:covid-19:doc::142863</td>\n",
       "      <td>11.282253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>id:covid-19:doc::187156</td>\n",
       "      <td>11.266751</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                   doc_id      score  rank\n",
       "0    0   id:covid-19:doc::31328  11.282253     0\n",
       "1    0  id:covid-19:doc::142863  11.282253     1\n",
       "2    0  id:covid-19:doc::187156  11.266751     2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flexible_result = app.query(query=\"this is a test\", query_model=flexible_query_model)\n",
    "flexible_result.get_hits().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-badge",
   "metadata": {},
   "source": [
    "## Query output format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-concert",
   "metadata": {},
   "source": [
    "* PR: [Make it possible to format query results](https://github.com/vespa-engine/pyvespa/pull/119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = app.query(query = \"this is a test\", query_model=query_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-candle",
   "metadata": {},
   "source": [
    "Full Vespa output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-center",
   "metadata": {},
   "source": [
    "Vespa hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-tutorial",
   "metadata": {},
   "source": [
    "Get formatted hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.get_hits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-particular",
   "metadata": {},
   "source": [
    "Choose `id_field` to be returned as `doc_id` column and specify desired `qid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.get_hits(id_field = \"cord_uid\", qid = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-victor",
   "metadata": {},
   "source": [
    "## Evaluation framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.evaluation import MatchRatio, Recall, ReciprocalRank\n",
    "\n",
    "eval_metrics = [MatchRatio(), Recall(at=10), eiddccidrbcvlbtnjiriejnrtgjeffggcdvrkcucrnnk\n",
    "                ReciprocalRank(at=10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-saturn",
   "metadata": {},
   "source": [
    "### Allow df as input to app.evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-requirement",
   "metadata": {},
   "source": [
    "* PR: [Support df as input to app.evaluate](https://github.com/vespa-engine/pyvespa/pull/120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-mailing",
   "metadata": {},
   "source": [
    "We accept two types of labeled_data format. The first is a DataFrame with [\"qid\", \"query\", \"doc_id\", \"relevance\"] columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "labeled_data_df = DataFrame(\n",
    "    data={\n",
    "        \"qid\": [0] * 2 + [1] * 2, \n",
    "        \"query\": [\"Intrauterine virus infections and congenital heart disease\"] * 2 + \n",
    "                 [\"Clinical and immunologic studies in identical twins discordant for systemic lupus erythematosus\"] * 2,\n",
    "        \"doc_id\": [120761, 145189, 49, 11317],\n",
    "        \"relevance\": [1,1,1,1]\n",
    "    }\n",
    ")\n",
    "labeled_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = app.evaluate(\n",
    "    labeled_data = labeled_data_df,\n",
    "    eval_metrics = eval_metrics,\n",
    "    query_model = query_model,\n",
    "    id_field = \"id\",\n",
    ")\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-deficit",
   "metadata": {},
   "source": [
    "The second input type is a list of dicts. It is a more concise version where we do not need to repeat `query_id` and `query` for every relevant document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = [\n",
    "    {\n",
    "        \"query_id\": 0, \n",
    "        \"query\": \"Intrauterine virus infections and congenital heart disease\",\n",
    "        \"relevant_docs\": [{\"id\": 120761, \"score\": 1}, {\"id\": 145189, \"score\": 1}]\n",
    "    },\n",
    "    {\n",
    "        \"query_id\": 1, \n",
    "        \"query\": \"Clinical and immunologic studies in identical twins discordant for systemic lupus erythematosus\",\n",
    "        \"relevant_docs\": [{\"id\": 49, \"score\": 1}, {\"id\": 11317, \"score\": 1}]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = app.evaluate(\n",
    "    labeled_data = labeled_data,\n",
    "    eval_metrics = eval_metrics,\n",
    "    query_model = query_model,\n",
    "    id_field = \"id\",\n",
    ")\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-chocolate",
   "metadata": {},
   "source": [
    "### Make app.evaluate return simplied metrics as default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-belly",
   "metadata": {},
   "source": [
    "* PR: [Simplified metrics output by default with option for detailed metrics](https://github.com/vespa-engine/pyvespa/pull/121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = app.evaluate(\n",
    "    labeled_data = labeled_data,\n",
    "    eval_metrics = eval_metrics,\n",
    "    query_model = query_model,\n",
    "    id_field = \"id\",\n",
    "    detailed_metrics = True\n",
    ")\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-czech",
   "metadata": {},
   "source": [
    "## Allow multiple query models as input to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-controversy",
   "metadata": {},
   "source": [
    "* PR: [Evaluate multiple query models](https://github.com/vespa-engine/pyvespa/pull/122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.query import QueryModel, RankProfile, OR, AND\n",
    "\n",
    "query_model_1 = QueryModel(\n",
    "    name=\"or_bm25\",\n",
    "    match_phase = OR(),\n",
    "    rank_profile = RankProfile(name=\"bm25\", list_features=True)\n",
    ")\n",
    "query_model_2 = QueryModel(\n",
    "    name=\"and_bm25\",\n",
    "    match_phase = AND(),\n",
    "    rank_profile = RankProfile(name=\"bm25\", list_features=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = app.evaluate(\n",
    "    labeled_data = labeled_data,\n",
    "    eval_metrics = eval_metrics,\n",
    "    query_model = [query_model_1, query_model_2],\n",
    "    id_field = \"id\",\n",
    ")\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-modem",
   "metadata": {},
   "source": [
    "### Make app.evaluate return aggregare metrics by default and add per_query = True as argument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-credit",
   "metadata": {},
   "source": [
    "* PR: [Enable per_query argument. Default to per model summary](https://github.com/vespa-engine/pyvespa/pull/124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = app.evaluate(\n",
    "    labeled_data = labeled_data,\n",
    "    eval_metrics = eval_metrics,\n",
    "    query_model = [query_model_1, query_model_2],\n",
    "    id_field = \"id\",\n",
    ")\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = app.evaluate(\n",
    "    labeled_data = labeled_data,\n",
    "    eval_metrics = eval_metrics,\n",
    "    query_model = [query_model_1, query_model_2],\n",
    "    id_field = \"id\",\n",
    "    aggregators = [\"max\", \"min\"]\n",
    ")\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = app.evaluate(\n",
    "    labeled_data = labeled_data,\n",
    "    eval_metrics = eval_metrics,\n",
    "    query_model = [query_model_1, query_model_2],\n",
    "    id_field = \"id\",\n",
    "    per_query = True\n",
    ")\n",
    "evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
