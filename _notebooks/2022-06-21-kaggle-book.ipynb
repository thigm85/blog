{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sorted-subscriber",
   "metadata": {},
   "source": [
    "# Notes about the book The Kaggle book\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [book, kaggle, data science]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d703b482",
   "metadata": {},
   "source": [
    "## Chapter 1 - Introducing Kaggle and other data science competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-announcement",
   "metadata": {},
   "source": [
    "* [Kaggle public API docs](https://www.kaggle.com/docs/api).\n",
    "* [Kaggle API Github repo](https://github.com/Kaggle/kaggle-api).\n",
    "* Tip: Interact with others on the discussion forum when enrolled on a competition to share and learn.\n",
    "* Common Task Framework (CTF): Great for advancing state of the art solutions.\n",
    "    * Well defined metrics and quality data\n",
    "    * Competition\n",
    "    * Sharing between competitors\n",
    "    * Compute-resource availability\n",
    "* What can go wrong in a competition:\n",
    "    * Leakeage from the data: data contain informatio of the target not available in real-time.\n",
    "    * Probing from the leaderboard: Use the leaderboard to metric to tune your solution.\n",
    "        * Example: https://www.kaggle.com/c/dont-overfit-ii/discussion/91766\n",
    "    * Overfitting and consequent leaderboard shake-up: cases with huge gap between the training set and the public test set\n",
    "        * Technique to measure discrepancies between training set and test set: https://www.kaggle.com/code/tunguz/adversarial-ieee/notebook\n",
    "    * Private sharing\n",
    "* Jeremy Howard on how to set you up for success on Kaggle: https://www.kaggle.com/code/jhoward/first-steps-road-to-the-top-part-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730f84e4",
   "metadata": {},
   "source": [
    "## Chapter 2 - Organizing Data with Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-identification",
   "metadata": {},
   "source": [
    "### Setting up a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-feeling",
   "metadata": {},
   "source": [
    "* It is possible to upload a dataset either privately or publicly.\n",
    "* It is possible to use \"Import a GitHub repository\" option to import a experimental library not yet available on Kaggle Notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-mayor",
   "metadata": {},
   "source": [
    "### Gathering data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-radical",
   "metadata": {},
   "source": [
    "* Interesting interview from [Larxel](https://www.kaggle.com/andrewmvd):\n",
    "    * On creating datasets:\n",
    "        * All in all, the process that I recommend starts with setting your purpose, breaking it down into objectives and topics, formulating questions to fulfil these topics, surveying possible sources of data, selecting and gathering, pre-processing, documenting, publishing, maintaining and supporting, and finally, improvement actions.\n",
    "    * On learning on Kaggle:\n",
    "        * Absorbing all the knowledge at the end of a competition\n",
    "        * Replication of winning solutions in finished competitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-definition",
   "metadata": {},
   "source": [
    "### Working with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-queens",
   "metadata": {},
   "source": [
    "* The easiest way to work with Kaggle datasets is by creating a notebook from the dataset webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-supplement",
   "metadata": {},
   "source": [
    "### Using Kaggle datasets in Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-birth",
   "metadata": {},
   "source": [
    "* This section contains a step-by-step to download Kaggle Datasets into Colab.\n",
    "    1. Download Kaggle API from your Kaggle account. Place it ~/.kaggle/kaggle.json\n",
    "    2. Create folder `Kaggle` on your GDrive and upload .json there.\n",
    "    3. Mount GDrive to your colab\n",
    "    ```\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    ```\n",
    "    4. Provide path to .json config\n",
    "    ```python\n",
    "    import os\n",
    "    # content/gdrive/My Drive/Kaggle is the path where kaggle.json is \n",
    "    # present in the Google Drive\n",
    "    os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
    "    # change the working directory\n",
    "    %cd /content/gdrive/My Drive/Kaggle\n",
    "    \n",
    "    ```\n",
    "    5. Go to the dataset page and use the `copy API command`.\n",
    "    6. Run the command on the colab. Ex.:\n",
    "    ```\n",
    "    !kaggle datasets download -d bricevergnou/spotify-recommendation\n",
    "    ```\n",
    "    7. Data is downloaded to `os.environ['KAGGLE_CONFIG_DIR']`. Unzip it and you are ready to go."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
