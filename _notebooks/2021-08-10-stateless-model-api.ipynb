{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "headed-complement",
   "metadata": {},
   "source": [
    "# Vespa stateless model evaluation\n",
    "> Experimennting with a python API\n",
    "\n",
    "- toc: true \n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [vespa, pyvespa, stateless model evaluation, huggingface]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-landing",
   "metadata": {},
   "source": [
    "## Text classification task with the Huggingface inference API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-radius",
   "metadata": {},
   "source": [
    "### Hosted API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abstract-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "headers = {\"Authorization\": \"Bearer api_mxMKsfJoFDmvPdPziZLGuymSBQMbxVYoWg\"}\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "atlantic-concern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NEGATIVE', 'score': 0.9670119881629944},\n",
       "  {'label': 'POSITIVE', 'score': 0.032987985759973526}]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = query({\"inputs\": \"This is a test\"})\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-broadcast",
   "metadata": {},
   "source": [
    "First time using the API, it returns an error indicating the it is loading the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-tuesday",
   "metadata": {},
   "source": [
    "```\n",
    "{'error': 'Model distilbert-base-uncased-finetuned-sst-2-english is currently loading',\n",
    " 'estimated_time': 20}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-depth",
   "metadata": {},
   "source": [
    "### Local with their python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vietnamese-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\"), \n",
    "    model=AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "thirty-stretch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9670119572344816, 0.032988042765518436]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "logits = pipeline(\"This is a test\").tolist()[0]\n",
    "[math.exp(x)/(math.exp(logits[0])+math.exp(logits[1])) for x in logits]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-taste",
   "metadata": {},
   "source": [
    "## Vespa stateless model api - the bare minumum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-incentive",
   "metadata": {},
   "source": [
    "### Create the application package and deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-cedar",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**: The step below assumes you exported a model to ONNX\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "commercial-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import ModelServer\n",
    "\n",
    "model_server = ModelServer(\n",
    "    name=\"bert_model_server\", \n",
    "    model_file_path = \"data/2021-08-10-stateless-model-api/bert_tiny.onnx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-access",
   "metadata": {},
   "source": [
    "Could just as easily deploy to Vespa Cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "comparative-commissioner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for configuration server.\n",
      "Waiting for configuration server.\n",
      "Waiting for configuration server.\n",
      "Finished deployment.\n"
     ]
    }
   ],
   "source": [
    "from vespa.deployment import VespaDocker\n",
    "\n",
    "disk_folder = \"/Users/tmartins/model_server_docker\"\n",
    "vespa_docker = VespaDocker(disk_folder=disk_folder, port=8081)\n",
    "app = vespa_docker.deploy(application_package=model_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-performance",
   "metadata": {},
   "source": [
    "## Interact with the application with Vespa REST api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-jordan",
   "metadata": {},
   "source": [
    "Get the models available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unlikely-estimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"bert_tiny\":\"http://localhost:8080/model-evaluation/v1/bert_tiny\"}"
     ]
    }
   ],
   "source": [
    "!curl -s 'http://localhost:8081/model-evaluation/v1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-traveler",
   "metadata": {},
   "source": [
    "Get information about a specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "floppy-karen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\":\"bert_tiny\",\"functions\":[{\"function\":\"output_0\",\"info\":\"http://localhost:8080/model-evaluation/v1/bert_tiny/output_0\",\"eval\":\"http://localhost:8080/model-evaluation/v1/bert_tiny/output_0/eval\",\"arguments\":[{\"name\":\"input_ids\",\"type\":\"tensor(d0[],d1[])\"},{\"name\":\"attention_mask\",\"type\":\"tensor(d0[],d1[])\"},{\"name\":\"token_type_ids\",\"type\":\"tensor(d0[],d1[])\"}]}]}"
     ]
    }
   ],
   "source": [
    "!curl -s 'http://localhost:8081/model-evaluation/v1/bert_tiny'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-doctor",
   "metadata": {},
   "source": [
    "Write custom code to generate url encoded inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-edinburgh",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**: Writing custom code to get the inputs right is messy and does not allow to improve speed unless the users writes their own custom java searcher.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sunset-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"google/bert_uncased_L-2_H-128_A-2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "empty-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode\n",
    "\n",
    "def create_url_encoded_input(text, tokenizer):\n",
    "    tokens = tokenizer(text)\n",
    "    encoded_tokens = urlencode(\n",
    "        {\n",
    "            key: \"{\"\n",
    "            + \",\".join(\n",
    "                [\n",
    "                    \"{{d0: 0, d1: {}}}: {}\".format(idx, x)\n",
    "                    for idx, x in enumerate(value)\n",
    "                ]\n",
    "            )\n",
    "            + \"}\"\n",
    "            for key, value in tokens.items()\n",
    "        }\n",
    "    )\n",
    "    return encoded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "successful-pioneer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input_ids=%7B%7Bd0%3A+0%2C+d1%3A+0%7D%3A+101%2C%7Bd0%3A+0%2C+d1%3A+1%7D%3A+2023%2C%7Bd0%3A+0%2C+d1%3A+2%7D%3A+2003%2C%7Bd0%3A+0%2C+d1%3A+3%7D%3A+1037%2C%7Bd0%3A+0%2C+d1%3A+4%7D%3A+3793%2C%7Bd0%3A+0%2C+d1%3A+5%7D%3A+102%7D&token_type_ids=%7B%7Bd0%3A+0%2C+d1%3A+0%7D%3A+0%2C%7Bd0%3A+0%2C+d1%3A+1%7D%3A+0%2C%7Bd0%3A+0%2C+d1%3A+2%7D%3A+0%2C%7Bd0%3A+0%2C+d1%3A+3%7D%3A+0%2C%7Bd0%3A+0%2C+d1%3A+4%7D%3A+0%2C%7Bd0%3A+0%2C+d1%3A+5%7D%3A+0%7D&attention_mask=%7B%7Bd0%3A+0%2C+d1%3A+0%7D%3A+1%2C%7Bd0%3A+0%2C+d1%3A+1%7D%3A+1%2C%7Bd0%3A+0%2C+d1%3A+2%7D%3A+1%2C%7Bd0%3A+0%2C+d1%3A+3%7D%3A+1%2C%7Bd0%3A+0%2C+d1%3A+4%7D%3A+1%2C%7Bd0%3A+0%2C+d1%3A+5%7D%3A+1%7D'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_tokens = create_url_encoded_input(\"this is a text\", tokenizer)\n",
    "encoded_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-roberts",
   "metadata": {},
   "source": [
    "Use the encoded tokens to get a prediction from Vespa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "finished-judgment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'address': {'d0': '0', 'd1': '0'}, 'value': -0.02798202447593212},\n",
       "  {'address': {'d0': '0', 'd1': '1'}, 'value': -0.1420438140630722}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from requests import get\n",
    "\n",
    "get(\"http://localhost:8081/model-evaluation/v1/bert_tiny/output_0/eval?{}\".format(encoded_tokens)).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-bearing",
   "metadata": {},
   "source": [
    "Clean up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "opened-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(disk_folder, ignore_errors=True)\n",
    "vespa_docker.container.stop()\n",
    "vespa_docker.container.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-helmet",
   "metadata": {},
   "source": [
    "## Vespa stateless model - full python api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-porter",
   "metadata": {},
   "source": [
    "Define the task and the model to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "banner-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.ml import SequenceClassification\n",
    "\n",
    "model = SequenceClassification(\n",
    "    model_id=\"bert_tiny\", \n",
    "    model=\"google/bert_uncased_L-2_H-128_A-2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-ordering",
   "metadata": {},
   "source": [
    "Create the application package, no need to manually export the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "romance-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import ModelServer\n",
    "\n",
    "model_server = ModelServer(\n",
    "    name=\"bert_model_server\",\n",
    "    models=[model],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-douglas",
   "metadata": {},
   "source": [
    "Deploy, could just as easily deploy to Vespa Cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "demographic-demographic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using framework PyTorch: 1.7.1\n",
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input token_type_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch'}\n",
      "Ensuring inputs are in correct order\n",
      "position_ids is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask', 'token_type_ids']\n",
      "Waiting for configuration server.\n",
      "Waiting for configuration server.\n",
      "Waiting for configuration server.\n",
      "Finished deployment.\n"
     ]
    }
   ],
   "source": [
    "from vespa.deployment import VespaDocker\n",
    "\n",
    "disk_folder = \"/Users/tmartins/model_server_docker\"\n",
    "vespa_docker = VespaDocker(disk_folder=disk_folder, port=8081)\n",
    "app = vespa_docker.deploy(application_package=model_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-audience",
   "metadata": {},
   "source": [
    "Get models available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "frequent-remainder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert_tiny': 'http://localhost:8080/model-evaluation/v1/bert_tiny'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.get_model_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-search",
   "metadata": {},
   "source": [
    "Get information about a specific model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eligible-resource",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'bert_tiny',\n",
       " 'functions': [{'function': 'output_0',\n",
       "   'info': 'http://localhost:8080/model-evaluation/v1/bert_tiny/output_0',\n",
       "   'eval': 'http://localhost:8080/model-evaluation/v1/bert_tiny/output_0/eval',\n",
       "   'arguments': [{'name': 'input_ids', 'type': 'tensor(d0[],d1[])'},\n",
       "    {'name': 'attention_mask', 'type': 'tensor(d0[],d1[])'},\n",
       "    {'name': 'token_type_ids', 'type': 'tensor(d0[],d1[])'}]}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.get_model_endpoint(\"bert_tiny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-transparency",
   "metadata": {},
   "source": [
    "Get a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "indie-contest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.009904447011649609, 0.04607260227203369]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.predict(x=\"this is a test\", model_name=\"bert_tiny\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
