{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d88733ee-3b4d-48dc-a468-0e0a406e4d83",
   "metadata": {},
   "source": [
    "# Simple baseline for YouTube 8M video-level features with TensorFlow\n",
    "> Getting started with TensorFlow API\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [youtube 8m, video data, tensorflow, training]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-eight",
   "metadata": {},
   "source": [
    "The goal of this blog post is to show how to use the TensorFlow API to create a multi-label logistic classification model that takes multiple inputs. The focus is not on the results as we will use just a sample dataset, but on the API itself. This post builds on [a previous blog post](https://thigm85.github.io/blog/youtube%208m/video%20data/tensorflow/2021/10/08/youtube-8m-video-level.html) that shows how to create a TensorFlow Dataset for [the YouTube 8M video-level dataset](https://research.google.com/youtube8m/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f16ca2-cc80-4949-a003-580e96ec4046",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd8440a-b070-4f6d-8fdb-0a2e62e07870",
   "metadata": {},
   "source": [
    "This code works with tensorflow 2.6.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8947bf-8951-4fb2-b99e-e2de5b169a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c1a08f-3ef8-4d55-83c0-9ac62d17787a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-payroll",
   "metadata": {},
   "source": [
    "## Load parsed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-taste",
   "metadata": {},
   "source": [
    "The parsed dataset created in [the previous blog post](https://thigm85.github.io/blog/youtube%208m/video%20data/tensorflow/2021/10/08/youtube-8m-video-level.html) was saved using `tf.data.experimental.save`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(parsed_dataset, os.path.join(data_folder, \"dataset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-energy",
   "metadata": {},
   "source": [
    "Load the parsed dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "medieval-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dataset = tf.data.experimental.load(os.path.join(os.environ[\"DATA_FOLDER\"], \"dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "boolean-surrey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'eACj'], dtype=object)>, 'labels': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([180, 304])>, 'mean_rgb': <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
      "array([ 0.34214902,  1.0072957 , -0.28980112, ..., -0.38452676,\n",
      "        0.07256398, -0.9404775 ], dtype=float32)>, 'mean_audio': <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
      "array([-1.5312055 , -1.0285152 ,  0.15257615, -1.3953794 , -0.5539142 ,\n",
      "        1.066028  , -1.8354464 ,  0.3552817 , -0.7087098 ,  0.95269775,\n",
      "       -0.35108703, -1.0913819 , -0.43328798, -0.13257357,  0.9500226 ,\n",
      "        1.6974918 ,  1.8891319 , -0.3803924 , -1.9713941 ,  1.7584128 ,\n",
      "       -0.551239  ,  0.13044512, -0.04392789, -1.3871107 , -1.3588997 ,\n",
      "       -0.08746034,  0.98711026,  0.00665731, -0.3661653 , -0.92649364,\n",
      "        0.11269166,  1.5400211 ,  0.5915486 , -1.6733549 , -0.5325128 ,\n",
      "       -0.9271016 , -1.7089834 ,  0.76628643, -1.054659  ,  0.4481834 ,\n",
      "       -0.21100494,  0.12168999, -0.22766402, -1.0156257 , -1.2115217 ,\n",
      "        0.42374197,  0.5706336 ,  0.06538964,  0.33071873, -0.04344149,\n",
      "        0.15525132, -1.0446879 , -0.78811395, -0.4171153 , -0.52485204,\n",
      "        0.4324971 , -0.6081474 ,  0.45110175, -0.13913992, -0.4041042 ,\n",
      "        0.2465722 ,  0.34263542, -1.3624262 , -0.04867025,  0.42751154,\n",
      "        0.3208692 ,  0.12728354, -1.0325279 ,  1.2633833 , -0.4146833 ,\n",
      "       -1.2371792 ,  0.17993592, -1.0372703 , -0.7702389 , -1.0303392 ,\n",
      "       -0.83468634,  1.5831887 , -0.43401757,  0.1333635 ,  1.0003645 ,\n",
      "        0.72445637,  0.50229496, -0.67599964,  0.96339846, -0.14984064,\n",
      "        1.27834   ,  1.491503  , -0.4544462 , -0.04380629, -0.7911539 ,\n",
      "       -0.16260853, -0.12308885,  0.5622433 , -0.909713  ,  0.7098645 ,\n",
      "       -1.4420735 ,  0.30895248, -1.7302632 , -0.14376068,  1.0689464 ,\n",
      "       -0.13062799,  0.5123877 ,  0.6601305 ,  1.0648121 ,  0.99878377,\n",
      "        0.43930665, -0.05961416, -0.0680045 , -0.37261006, -1.1954707 ,\n",
      "       -0.9128745 ,  0.6335003 , -1.6354159 ,  0.00629251,  1.1883566 ,\n",
      "        1.6427722 ,  0.48028553,  0.5267363 , -0.80732656, -0.8823532 ,\n",
      "       -1.0776412 ,  1.2457514 ,  0.06478164,  0.05408093, -0.54844224,\n",
      "        0.1208388 , -0.78628993,  0.5823071 ], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for parsed_record in parsed_dataset.take(1):\n",
    "  print(repr(parsed_record))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-eugene",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-cleveland",
   "metadata": {},
   "source": [
    "Builds a multi-label logistic classification model that takes the image and audio vectors as input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-arctic",
   "metadata": {},
   "source": [
    "### Number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-stamp",
   "metadata": {},
   "source": [
    "According to [the YouTube 8M video-level dataset](https://research.google.com/youtube8m/index.html) there are 3862 classes. We can check if our sample data has at most 3862 different labels. It is a good opportunity to use the `tf.Dataset.reduce` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "improving-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_reduce_unique_values(old, new):\n",
    "    concat_tensor = tf.concat([old, new[\"labels\"]], axis = 0)\n",
    "    y, _ = tf.unique(concat_tensor)\n",
    "    return y\n",
    "\n",
    "unique_labels = tf.sort(parsed_dataset.reduce(\n",
    "    np.array([], dtype=np.int64), tf_reduce_unique_values\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "miniature-cooling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3687,), dtype=int64, numpy=array([   0,    1,    2, ..., 3859, 3860, 3861])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "useful-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert unique_labels[-1] <= 3861 # The dataset has a total of 3862 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-residence",
   "metadata": {},
   "source": [
    "We can then define the number of classes to be 3862:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "agreed-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_classes = 3862"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-director",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-input",
   "metadata": {},
   "source": [
    "Use keras functional API to define a multiple inputs model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "impressive-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rgb = keras.Input(name=\"mean_rgb\", shape=(1024,))\n",
    "mean_audio = keras.Input(name=\"mean_audio\", shape=(128,))\n",
    "x = keras.layers.concatenate([mean_rgb, mean_audio])\n",
    "x = keras.layers.Dense(activation=\"sigmoid\", units=number_classes)(x)\n",
    "model = keras.Model(inputs=[mean_rgb, mean_audio], outputs=[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-restriction",
   "metadata": {},
   "source": [
    "### Compile  the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-feature",
   "metadata": {},
   "source": [
    "Since each video can belong to more than one class, we need to build a multi-label classification model. We can then use the binary crossentropy loss function and the binary accuracy metric for reasons discussed in [this blog post](https://medium.com/deep-learning-with-keras/how-to-solve-multi-label-classification-problems-in-deep-learning-with-tensorflow-keras-7fb933243595)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "actual-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-starter",
   "metadata": {},
   "source": [
    "### Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-nylon",
   "metadata": {},
   "source": [
    "The keras training API accepts a `tf.Dataset` as input but it expects a tuple containing `(features, labels)`. We need then to preprocess our `parsed_dataset` to turn it into a `train_dataset` with appropriate output format. We also need to transform the labels from a list of integers to a multi-hot encoding as desccribed in [this blog post](https://thigm85.github.io/blog/tensorflow/multi-label%20classification/2021/10/18/multi-label-encoding-tensorflow.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "enhanced-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_preprocessing(data, number_classes):\n",
    "    features = {\"mean_rgb\": data[\"mean_rgb\"], \"mean_audio\": data[\"mean_audio\"]}\n",
    "    one_hot = tf.one_hot(indices=data[\"labels\"], depth=number_classes)\n",
    "    label = tf.reduce_max(one_hot, axis = 0)\n",
    "    return (features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dedicated-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = parsed_dataset.map(lambda x: training_preprocessing(x, number_classes=number_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "australian-noise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'mean_rgb': <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
      "array([ 0.34214902,  1.0072957 , -0.28980112, ..., -0.38452676,\n",
      "        0.07256398, -0.9404775 ], dtype=float32)>, 'mean_audio': <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
      "array([-1.5312055 , -1.0285152 ,  0.15257615, -1.3953794 , -0.5539142 ,\n",
      "        1.066028  , -1.8354464 ,  0.3552817 , -0.7087098 ,  0.95269775,\n",
      "       -0.35108703, -1.0913819 , -0.43328798, -0.13257357,  0.9500226 ,\n",
      "        1.6974918 ,  1.8891319 , -0.3803924 , -1.9713941 ,  1.7584128 ,\n",
      "       -0.551239  ,  0.13044512, -0.04392789, -1.3871107 , -1.3588997 ,\n",
      "       -0.08746034,  0.98711026,  0.00665731, -0.3661653 , -0.92649364,\n",
      "        0.11269166,  1.5400211 ,  0.5915486 , -1.6733549 , -0.5325128 ,\n",
      "       -0.9271016 , -1.7089834 ,  0.76628643, -1.054659  ,  0.4481834 ,\n",
      "       -0.21100494,  0.12168999, -0.22766402, -1.0156257 , -1.2115217 ,\n",
      "        0.42374197,  0.5706336 ,  0.06538964,  0.33071873, -0.04344149,\n",
      "        0.15525132, -1.0446879 , -0.78811395, -0.4171153 , -0.52485204,\n",
      "        0.4324971 , -0.6081474 ,  0.45110175, -0.13913992, -0.4041042 ,\n",
      "        0.2465722 ,  0.34263542, -1.3624262 , -0.04867025,  0.42751154,\n",
      "        0.3208692 ,  0.12728354, -1.0325279 ,  1.2633833 , -0.4146833 ,\n",
      "       -1.2371792 ,  0.17993592, -1.0372703 , -0.7702389 , -1.0303392 ,\n",
      "       -0.83468634,  1.5831887 , -0.43401757,  0.1333635 ,  1.0003645 ,\n",
      "        0.72445637,  0.50229496, -0.67599964,  0.96339846, -0.14984064,\n",
      "        1.27834   ,  1.491503  , -0.4544462 , -0.04380629, -0.7911539 ,\n",
      "       -0.16260853, -0.12308885,  0.5622433 , -0.909713  ,  0.7098645 ,\n",
      "       -1.4420735 ,  0.30895248, -1.7302632 , -0.14376068,  1.0689464 ,\n",
      "       -0.13062799,  0.5123877 ,  0.6601305 ,  1.0648121 ,  0.99878377,\n",
      "        0.43930665, -0.05961416, -0.0680045 , -0.37261006, -1.1954707 ,\n",
      "       -0.9128745 ,  0.6335003 , -1.6354159 ,  0.00629251,  1.1883566 ,\n",
      "        1.6427722 ,  0.48028553,  0.5267363 , -0.80732656, -0.8823532 ,\n",
      "       -1.0776412 ,  1.2457514 ,  0.06478164,  0.05408093, -0.54844224,\n",
      "        0.1208388 , -0.78628993,  0.5823071 ], dtype=float32)>}, <tf.Tensor: shape=(3862,), dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "for data in train_dataset.take(1):\n",
    "  print(repr(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-beach",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-catholic",
   "metadata": {},
   "source": [
    "We can then use the `fit` method with the `train_dataset` that we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "electrical-combination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1294/1294 [==============================] - 55s 42ms/step - loss: 0.4018 - binary_accuracy: 0.8924\n",
      "Epoch 2/3\n",
      "1294/1294 [==============================] - 55s 43ms/step - loss: 0.1287 - binary_accuracy: 0.9953\n",
      "Epoch 3/3\n",
      "1294/1294 [==============================] - 54s 42ms/step - loss: 0.0399 - binary_accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17eb4c640>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset.batch(32), epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
