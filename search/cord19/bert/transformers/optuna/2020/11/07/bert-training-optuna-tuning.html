<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Fine-tuning a BERT model for search applications with Optuna tuning | Thiago G. Martins</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Fine-tuning a BERT model for search applications with Optuna tuning" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Fine-tune BERT models using Optuna for hyperparameter tuning" />
<meta property="og:description" content="Fine-tune BERT models using Optuna for hyperparameter tuning" />
<link rel="canonical" href="https://thigm85.github.io/blog/search/cord19/bert/transformers/optuna/2020/11/07/bert-training-optuna-tuning.html" />
<meta property="og:url" content="https://thigm85.github.io/blog/search/cord19/bert/transformers/optuna/2020/11/07/bert-training-optuna-tuning.html" />
<meta property="og:site_name" content="Thiago G. Martins" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-07T00:00:00-06:00" />
<script type="application/ld+json">
{"description":"Fine-tune BERT models using Optuna for hyperparameter tuning","mainEntityOfPage":{"@type":"WebPage","@id":"https://thigm85.github.io/blog/search/cord19/bert/transformers/optuna/2020/11/07/bert-training-optuna-tuning.html"},"@type":"BlogPosting","url":"https://thigm85.github.io/blog/search/cord19/bert/transformers/optuna/2020/11/07/bert-training-optuna-tuning.html","headline":"Fine-tuning a BERT model for search applications with Optuna tuning","dateModified":"2020-11-07T00:00:00-06:00","datePublished":"2020-11-07T00:00:00-06:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://thigm85.github.io/blog/feed.xml" title="Thiago G. Martins" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-28943273-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Fine-tuning a BERT model for search applications with Optuna tuning | Thiago G. Martins</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Fine-tuning a BERT model for search applications with Optuna tuning" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Fine-tune BERT models using Optuna for hyperparameter tuning" />
<meta property="og:description" content="Fine-tune BERT models using Optuna for hyperparameter tuning" />
<link rel="canonical" href="https://thigm85.github.io/blog/search/cord19/bert/transformers/optuna/2020/11/07/bert-training-optuna-tuning.html" />
<meta property="og:url" content="https://thigm85.github.io/blog/search/cord19/bert/transformers/optuna/2020/11/07/bert-training-optuna-tuning.html" />
<meta property="og:site_name" content="Thiago G. Martins" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-07T00:00:00-06:00" />
<script type="application/ld+json">
{"description":"Fine-tune BERT models using Optuna for hyperparameter tuning","mainEntityOfPage":{"@type":"WebPage","@id":"https://thigm85.github.io/blog/search/cord19/bert/transformers/optuna/2020/11/07/bert-training-optuna-tuning.html"},"@type":"BlogPosting","url":"https://thigm85.github.io/blog/search/cord19/bert/transformers/optuna/2020/11/07/bert-training-optuna-tuning.html","headline":"Fine-tuning a BERT model for search applications with Optuna tuning","dateModified":"2020-11-07T00:00:00-06:00","datePublished":"2020-11-07T00:00:00-06:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://thigm85.github.io/blog/feed.xml" title="Thiago G. Martins" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-28943273-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>


    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
<script type="text/javascript">
require.config({
  paths: {
    jquery: 'https://code.jquery.com/jquery-3.5.0.min',
    plotly: 'https://cdn.plot.ly/plotly-latest.min'
  },

  shim: {
    plotly: {
      deps: ['jquery'],
      exports: 'plotly'
    }
  }
});
</script>

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Thiago G. Martins</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Fine-tuning a BERT model for search applications with Optuna tuning</h1><p class="page-description">Fine-tune BERT models using Optuna for hyperparameter tuning</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-11-07T00:00:00-06:00" itemprop="datePublished">
        Nov 7, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      5 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#search">search</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#cord19">cord19</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#BERT">BERT</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#transformers">transformers</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#optuna">optuna</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/thigm85/blog/tree/master/_notebooks/2020-11-07-bert-training-optuna-tuning.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          <div class="px-2">
    <a href="https://colab.research.google.com/github/thigm85/blog/blob/master/_notebooks/2020-11-07-bert-training-optuna-tuning.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#In-case-running-on-Google-Colab">In case running on Google Colab </a></li>
<li class="toc-entry toc-h2"><a href="#Prepare-the-dataset">Prepare the dataset </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Load-the-data">Load the data </a></li>
<li class="toc-entry toc-h3"><a href="#Compatible-BERT-encodings">Compatible BERT encodings </a></li>
<li class="toc-entry toc-h3"><a href="#Create-Datasets">Create Datasets </a></li>
<li class="toc-entry toc-h3"><a href="#Fine-tune-the-BERT-model">Fine-tune the BERT model </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-11-07-bert-training-optuna-tuning.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="In-case-running-on-Google-Colab">
<a class="anchor" href="#In-case-running-on-Google-Colab" aria-hidden="true"><span class="octicon octicon-link"></span></a>In case running on Google Colab<a class="anchor-link" href="#In-case-running-on-Google-Colab"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Mount your Google Drive to be able to load and save data to it.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">'/content/drive'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Mounted at /content/drive
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Install libraries used in this post.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install transformers torch onnxruntime optuna
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Prepare-the-dataset">
<a class="anchor" href="#Prepare-the-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Prepare the dataset<a class="anchor-link" href="#Prepare-the-dataset"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-the-data">
<a class="anchor" href="#Load-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Load the data<a class="anchor-link" href="#Load-the-data"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In order to fine-tune the BERT models for the cord19 application we need to generate a set of query-document features as well as labels that indicate which documents are relevant for the specific queries. For this exercise we will use the <code>query</code> string to represent the query and the <code>title</code> string to represent the documents.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The file <code>labelled_data.json</code> contains information about the <code>query</code> string and the file <code>training_all_judgement_data.csv</code> contain information about labels and <code>title</code> string. Those files were created and covered elsewhere but you can download them <a href="https://drive.google.com/file/d/1R2hZTF6QBKPMaiuS4Du6aXQlBVnfZOAA/view?usp=sharing">here</a> and <a href="https://drive.google.com/file/d/18jNRM7G7agbO1Mg9t0l1pvqsz-qwEXpz/view?usp=sharing">here</a>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">read_csv</span>

<span class="n">labelled_data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s2">"/content/drive/My Drive/cord19/labelled_data_all.json"</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">))</span>
<span class="n">training_data</span> <span class="o">=</span> <span class="n">read_csv</span><span class="p">(</span><span class="s2">"/content/drive/My Drive/cord19/training_all_jugdments_data.csv"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>training_data</code> has almost everything we need, except the <code>query</code> string.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">training_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>document_id</th>
      <th>query_id</th>
      <th>label</th>
      <th>title-full</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>005b2j4b</td>
      <td>1</td>
      <td>2</td>
      <td>Monophyletic Relationship between Severe Acute...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>00fmeepz</td>
      <td>1</td>
      <td>1</td>
      <td>Comprehensive overview of COVID-19 based on cu...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>010vptx3</td>
      <td>1</td>
      <td>2</td>
      <td>The SARS, MERS and novel coronavirus (COVID-19...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0194oljo</td>
      <td>1</td>
      <td>1</td>
      <td>Evidence for zoonotic origins of Middle East r...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>021q9884</td>
      <td>1</td>
      <td>1</td>
      <td>Deadly virus effortlessly hops species</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The query string can be obtained from the <code>labelled_data</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">labelled_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">"query_id"</span><span class="p">],</span> <span class="n">labelled_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">"query"</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>1 coronavirus origin
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Compatible-BERT-encodings">
<a class="anchor" href="#Compatible-BERT-encodings" aria-hidden="true"><span class="octicon octicon-link"></span></a>Compatible BERT encodings<a class="anchor-link" href="#Compatible-BERT-encodings"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since we are training a model that will be deployed in a search application, we need to ensure that the training encodings are compatible with encodings used at serving time. At serving time, document encodings will be applied offline when feeding the documents to the search engine while the query encoding will be applied at run-time upon arrival of the query. In addition, it might be relevant to use different maximum length for queries and documents.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">create_bert_encodings</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">docs</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">query_input_size</span><span class="p">,</span> <span class="n">doc_input_size</span><span class="p">):</span>
    <span class="n">queries_encodings</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">queries</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">query_input_size</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="n">docs_encodings</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">docs</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">doc_input_size</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    
    <span class="n">TOKEN_NONE</span><span class="o">=</span><span class="mi">0</span>
    <span class="n">TOKEN_CLS</span><span class="o">=</span><span class="mi">101</span>
    <span class="n">TOKEN_SEP</span><span class="o">=</span><span class="mi">102</span>

    <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">token_type_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">attention_mask</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">query_input_ids</span><span class="p">,</span> <span class="n">doc_input_ids</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">queries_encodings</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">],</span> <span class="n">docs_encodings</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]):</span>
        <span class="c1"># create input id</span>
        <span class="n">input_id</span> <span class="o">=</span> <span class="p">[</span><span class="n">TOKEN_CLS</span><span class="p">]</span> <span class="o">+</span> <span class="n">query_input_ids</span> <span class="o">+</span> <span class="p">[</span><span class="n">TOKEN_SEP</span><span class="p">]</span> <span class="o">+</span> <span class="n">doc_input_ids</span> <span class="o">+</span> <span class="p">[</span><span class="n">TOKEN_SEP</span><span class="p">]</span>
        <span class="n">number_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_id</span><span class="p">)</span>
        <span class="n">padding_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">128</span> <span class="o">-</span> <span class="n">number_tokens</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">input_id</span> <span class="o">=</span> <span class="n">input_id</span> <span class="o">+</span> <span class="p">[</span><span class="n">TOKEN_NONE</span><span class="p">]</span> <span class="o">*</span> <span class="n">padding_length</span>
        <span class="n">input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_id</span><span class="p">)</span>
        <span class="c1"># create token id</span>
        <span class="n">token_type_id</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">([</span><span class="n">TOKEN_CLS</span><span class="p">]</span> <span class="o">+</span> <span class="n">query_input_ids</span> <span class="o">+</span> <span class="p">[</span><span class="n">TOKEN_SEP</span><span class="p">])</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">doc_input_ids</span> <span class="o">+</span> <span class="p">[</span><span class="n">TOKEN_SEP</span><span class="p">])</span> <span class="o">+</span> <span class="p">[</span><span class="n">TOKEN_NONE</span><span class="p">]</span> <span class="o">*</span> <span class="n">padding_length</span>
        <span class="n">token_type_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_type_id</span><span class="p">)</span>
        <span class="c1"># create attention_mask</span>
        <span class="n">attention_mask</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">number_tokens</span> <span class="o">+</span> <span class="p">[</span><span class="n">TOKEN_NONE</span><span class="p">]</span> <span class="o">*</span> <span class="n">padding_length</span><span class="p">)</span>

    <span class="n">encodings</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"input_ids"</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span>
        <span class="s2">"token_type_ids"</span><span class="p">:</span> <span class="n">token_type_ids</span><span class="p">,</span>
        <span class="s2">"attention_mask"</span><span class="p">:</span> <span class="n">attention_mask</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">encodings</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Create-Datasets">
<a class="anchor" href="#Create-Datasets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Create Datasets<a class="anchor-link" href="#Create-Datasets"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Create a list for queries (represented by the query string), docs (represented by the doc titles) and labels from the <code>labelled_data</code> and <code>training_data</code> that we loaded earlier.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_queries</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_docs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">data_point</span> <span class="ow">in</span> <span class="n">labelled_data</span><span class="p">:</span>
    <span class="n">query_id</span> <span class="o">=</span> <span class="n">data_point</span><span class="p">[</span><span class="s2">"query_id"</span><span class="p">]</span>
    <span class="n">titles</span> <span class="o">=</span> <span class="n">training_data</span><span class="p">[</span><span class="n">training_data</span><span class="p">[</span><span class="s2">"query_id"</span><span class="p">]</span> <span class="o">==</span> <span class="n">query_id</span><span class="p">][</span><span class="s2">"title-full"</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">train_docs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">titles</span><span class="p">)</span>
    <span class="n">train_labels</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">training_data</span><span class="p">[</span><span class="n">training_data</span><span class="p">[</span><span class="s2">"query_id"</span><span class="p">]</span> <span class="o">==</span> <span class="n">query_id</span><span class="p">][</span><span class="s2">"label"</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()])</span>
    <span class="n">query</span> <span class="o">=</span> <span class="n">data_point</span><span class="p">[</span><span class="s2">"query"</span><span class="p">]</span>
    <span class="n">train_queries</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">query</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">titles</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We are going to use a simple data split into train and validation sets for illustration purposes. The cord19 use case probably needs cross-validation to be used since it has only 50 queries containing relevance judgement.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">train_queries</span><span class="p">,</span> <span class="n">val_queries</span><span class="p">,</span> <span class="n">train_docs</span><span class="p">,</span> <span class="n">val_docs</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">val_labels</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">train_queries</span><span class="p">,</span> <span class="n">train_docs</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=.</span><span class="mi">2</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Create train and validation encodings. In order to do that we need to chose which BERT model to use, and the maximum size used for the resulting query and document vector.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_name</span> <span class="o">=</span> <span class="s2">"google/bert_uncased_L-4_H-512_A-8"</span>
<span class="n">query_input_size</span><span class="o">=</span><span class="mi">24</span>
<span class="n">doc_input_size</span><span class="o">=</span><span class="mi">64</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizerFast</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizerFast</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="n">train_encodings</span> <span class="o">=</span> <span class="n">create_bert_encodings</span><span class="p">(</span>
    <span class="n">queries</span><span class="o">=</span><span class="n">train_queries</span><span class="p">,</span> 
    <span class="n">docs</span><span class="o">=</span><span class="n">train_docs</span><span class="p">,</span> 
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> 
    <span class="n">query_input_size</span><span class="o">=</span><span class="n">query_input_size</span><span class="p">,</span> 
    <span class="n">doc_input_size</span><span class="o">=</span><span class="n">doc_input_size</span>
<span class="p">)</span>

<span class="n">val_encodings</span> <span class="o">=</span> <span class="n">create_bert_encodings</span><span class="p">(</span>
    <span class="n">queries</span><span class="o">=</span><span class="n">val_queries</span><span class="p">,</span> 
    <span class="n">docs</span><span class="o">=</span><span class="n">val_docs</span><span class="p">,</span> 
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> 
    <span class="n">query_input_size</span><span class="o">=</span><span class="n">query_input_size</span><span class="p">,</span> 
    <span class="n">doc_input_size</span><span class="o">=</span><span class="n">doc_input_size</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have the encodings and the labels we can create a <code>Dataset</code> object as described in the transformers webpage about <a href="https://huggingface.co/transformers/custom_datasets.html">custom datasets</a>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">Cord19Dataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encodings</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encodings</span> <span class="o">=</span> <span class="n">encodings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">item</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">val</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">encodings</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">'labels'</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">item</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">Cord19Dataset</span><span class="p">(</span><span class="n">train_encodings</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">Cord19Dataset</span><span class="p">(</span><span class="n">val_encodings</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Fine-tune-the-BERT-model">
<a class="anchor" href="#Fine-tune-the-BERT-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Fine-tune the BERT model<a class="anchor-link" href="#Fine-tune-the-BERT-model"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can then fine-tune the model (only task specific weights).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Define accuracy metric.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">EvalPrediction</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">p</span><span class="p">:</span> <span class="n">EvalPrediction</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">predictions</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="n">p</span><span class="o">.</span><span class="n">predictions</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">"accuracy"</span><span class="p">:</span> <span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">label_ids</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Hyperparameter tunning with Optuna.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">TrainingArguments</span>

<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s1">'/content/results'</span><span class="p">,</span>    <span class="c1"># output directory</span>
    <span class="c1">#evaluation_strategy="epoch",     # Evaluation is done at the end of each epoch.</span>
    <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">"steps"</span><span class="p">,</span>      <span class="c1"># Evaluation is done (and logged) every eval_steps.</span>
    <span class="n">eval_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>                  <span class="c1"># Number of update steps between two evaluations </span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>    <span class="c1"># batch size for evaluation</span>
    <span class="n">save_total_limit</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>               <span class="c1"># limit the total amount of checkpoints. Deletes the older checkpoints.</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">model_init</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">base_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>                  <span class="c1"># training arguments, defined above</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>         <span class="c1"># training dataset</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">val_dataset</span><span class="p">,</span>            <span class="c1"># evaluation dataset</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>     <span class="c1"># metrics to be computed</span>
    <span class="n">model_init</span><span class="o">=</span><span class="n">model_init</span>                <span class="c1"># Instantiate model before training starts</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">my_hp_space</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">"learning_rate"</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">"learning_rate"</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="s2">"num_train_epochs"</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">"num_train_epochs"</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
        <span class="s2">"seed"</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">"seed"</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">40</span><span class="p">),</span>
        <span class="s2">"per_device_train_batch_size"</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="s2">"per_device_train_batch_size"</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">]),</span>
    <span class="p">}</span>
<span class="k">def</span> <span class="nf">my_objective</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">metrics</span><span class="p">[</span><span class="s2">"eval_loss"</span><span class="p">]</span>

<span class="n">best_run</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">hyperparameter_search</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s2">"minimize"</span><span class="p">,</span> <span class="n">hp_space</span><span class="o">=</span><span class="n">my_hp_space</span><span class="p">,</span> <span class="n">compute_objective</span><span class="o">=</span><span class="n">my_objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">"/content/drive/My Drive/cord19/best_run.json"</span><span class="p">,</span> <span class="s2">"w+"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">best_run</span><span class="o">.</span><span class="n">hyperparameters</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Inspect best parameters</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_run</span><span class="o">.</span><span class="n">hyperparameters</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Retrain using the best parameters and the entire dataset (need to create <code>complete_dataset</code>)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s1">'/content/results'</span><span class="p">,</span>   <span class="c1"># output directory</span>
    <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">"epoch"</span><span class="p">,</span>     <span class="c1"># Evaluation is done at the end of each epoch.</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>   <span class="c1"># batch size for evaluation</span>
    <span class="n">save_total_limit</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>              <span class="c1"># limit the total amount of checkpoints. Deletes the older checkpoints.</span>
    <span class="o">**</span><span class="n">best_run</span><span class="o">.</span><span class="n">hyperparameters</span>    
<span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>                  <span class="c1"># training arguments, defined above</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">complte_dataset</span><span class="p">,</span>       <span class="c1"># training dataset</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>     <span class="c1"># metrics to be computed</span>
    <span class="n">model_init</span><span class="o">=</span><span class="n">model_init</span>                <span class="c1"># Instantiate model before training starts</span>
<span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

</div>

<script type="application/vnd.jupyter.widget-state+json">
{"16fe92ebfdbd4dcbb21a854c9dbf23b2": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "Downloading: 100%", "description_tooltip": null, "layout": "IPY_MODEL_e78d46e114d5488da8bb7da99ad30667", "max": 231508, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_a6e07f456d934b95af3d47a6ec727139", "value": 231508}}, "47f36ef2ccc4478a992dfec402b31f26": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_16fe92ebfdbd4dcbb21a854c9dbf23b2", "IPY_MODEL_59f8f75ad4af48aea7f4beae50f747b1"], "layout": "IPY_MODEL_c8a1744c21884bd79f9417e2b4975ee1"}}, "59f8f75ad4af48aea7f4beae50f747b1": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_e5d90277ef0944818b3966a78e209fab", "placeholder": "\u200b", "style": "IPY_MODEL_720306211d054294b654aa8641011c0a", "value": " 232k/232k [00:01&lt;00:00, 152kB/s]"}}, "720306211d054294b654aa8641011c0a": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "a6e07f456d934b95af3d47a6ec727139": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": "initial"}}, "c8a1744c21884bd79f9417e2b4975ee1": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e5d90277ef0944818b3966a78e209fab": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e78d46e114d5488da8bb7da99ad30667": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}}
</script>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="thigm85/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/search/cord19/bert/transformers/optuna/2020/11/07/bert-training-optuna-tuning.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Personal blog.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/thigm85" title="thigm85"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/Thiagogm" title="Thiagogm"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
